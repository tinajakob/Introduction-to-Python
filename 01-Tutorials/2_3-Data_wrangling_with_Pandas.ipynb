{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Gwwx6YFTV9Vt"},"source":["\n","*Part 2: Python for Data Analysis III*\n","# Data wrangling with Pandas#"]},{"cell_type":"markdown","metadata":{"id":"kK_V17EoSWpE"},"source":["In the last tutorial we got to know some useful functions and methods to import, inspect, clean and export data.\n","\n","The main focus of this tutorial will be on how to **prepare data for data analysis**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NyrHqgIjRGsT"},"source":["## Getting help"]},{"cell_type":"markdown","metadata":{"id":"b5yC0ZimQ2SE"},"source":["In this class we will not be able to cover all aspects of Python. If you want more details, you can consult, for example, the **Python Standard Library Reference** at https://docs.python.org/3/library/ or the **Language Reference** at https://docs.python.org/3/reference/. But be warned: the amount of detail in these sources can be overwhelming. For **quick and easy-to-understand overviews** of different topics see, for example, https://www.w3schools.com/python/. Here are some specific references for today's tutorial:\n","\n","*  Pandas: https://www.w3schools.com/python/pandas/default.asp\n","*  Statsmodels: https://www.statsmodels.org/stable/user-guide.html\n","*  Matplotlib: https://www.w3schools.com/python/matplotlib_pyplot.asp\n","*  Merging: https://pandas.pydata.org/docs/user_guide/merging.html\n","\n","\n","If you get stuck or don't remember how to do something, it is usually a good idea to **Google** your problem. Python has a large (and fast-growing) community and you will probably find answers to most of your questions online (e.g. on **Stack Overflow** or in a **Youtube tutorial**)."]},{"cell_type":"markdown","metadata":{"id":"a25uPN0lGfCn"},"source":["## Getting started"]},{"cell_type":"markdown","metadata":{"id":"NUNjq7KgR8bs"},"source":["For this tutorial, we will work with the following datasets:\n","\n","* ``life_satisfaction_clean.csv``\n","* ``trust_clean.csv``\n","* ``real-gdp-per-capita.csv``\n","\n","You can find them in the following folder: https://drive.google.com/drive/folders/1MG5FdPPx9XR2cZJmG5BqH-xq6RSQwg5J\n","\n","Copy them to an appropriate folder on your computer or your Google Drive so you can follow along with the Tutorial. Let's import the modules we will use, mount our drive, change our working directory and load in the data:"]},{"cell_type":"code","metadata":{"id":"ZgY9f8udvmbm"},"source":["import pandas as pd\n","import numpy as np\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPKBJfYCvqgt"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kFG1gPZ-UDVX"},"source":["os.chdir(\"/content/drive/MyDrive/MyData\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6qlLiHDwHuF"},"source":["satisfaction = pd.read_csv(\"life_satisfaction_clean.csv\", index_col=\"country\")\n","trust = pd.read_csv(\"trust_clean.csv\", index_col=\"country_code\")\n","gdp = pd.read_csv(\"real-gdp-per-capita.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LTnJrSFTwjDV"},"source":["If you didn't succeed to load the files, run the following lines of code to load them:"]},{"cell_type":"code","metadata":{"id":"dpay1KIwUASH"},"source":["satisfaction = pd.read_csv(\"http://farys.org/daten/life_satisfaction_clean.csv\",\n","                           index_col=\"country\")\n","\n","trust = pd.read_csv(\"http://farys.org/daten/trust_clean.csv\",\n","                    index_col=\"country_code\")\n","\n","gdp = pd.read_csv(\"http://farys.org/daten/real-gdp-per-capita.csv\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qCkSZzix-36"},"source":["## Combining datasets"]},{"cell_type":"markdown","metadata":{"id":"eaJK8uTsNCoq"},"source":["When you work with data, you will often have to combine different datasets. There are four pandas functions or methods that allow you to do this:\n","\n","* ``append`` method: Append rows\n","* ``concat`` function: Append rows or columns\n","* ``join`` method: Combine data on common indices\n","* ``merge`` function or method (both exist): Combine data on common columns or indices\n","\n","In this tutorial, we will only focus on ``concat`` and ``merge``, as they allow you to do everything (and more) you can do with ``append`` and ``join``.\n"]},{"cell_type":"markdown","metadata":{"id":"ooHLYntxyVWd"},"source":["### Concatenating"]},{"cell_type":"markdown","metadata":{"id":"9q7n2StEQ0c_"},"source":["Suppose you have your data in two different dataframes. Let's create this situation:"]},{"cell_type":"code","metadata":{"id":"FptjNwGKQPmm"},"source":["countries1 = satisfaction.loc[[\"Switzerland\", \"Tanzania\", \"Peru\"],\n","                              [\"continent\", \"life_satisfaction\"]]\n","countries1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYlCcuImr4vO"},"source":["countries2 = satisfaction.loc[[\"China\", \"India\"],\n","                              [\"continent\", \"life_satisfaction\"]]\n","countries2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iw_pGIbJQNLX"},"source":["Some countries are in ``countries1`` while others are in ``countries2``. How could we **combine them into a single dataframe**? The **``concat`` function** allows you to do this:"]},{"cell_type":"code","metadata":{"id":"kIEzVSpsSoMW"},"source":["countries = pd.concat([countries1, countries2])\n","countries"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wXae9d6TWA1"},"source":["As the (first) argument, you need to **provide a list of dataframes** (or series). Then, the rows are just stacked on top of each other.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oP7DZmqSuD7U"},"source":["\n","You can also use ``concat`` to combine data **columnwise**. Suppose we have the following two dataframes we would like to combine:"]},{"cell_type":"code","metadata":{"id":"sRmgLBfJS1Mf"},"source":["countries_left = satisfaction.loc[[\"Switzerland\", \"Tanzania\", \"Peru\"],\n","                                  [\"continent\", \"life_satisfaction\"]]\n","countries_left"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4L0Xz7FJVN8P"},"source":["countries_right = satisfaction.loc[[\"Switzerland\", \"Tanzania\", \"Peru\"],\n","                                   [\"gni_per_capita\", \"population\"]]\n","countries_right"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uwFN6hJfVaq1"},"source":["To **concatenate dataframes columnwise, we need to set the ``axis`` parameter to 1**:"]},{"cell_type":"code","metadata":{"id":"42NmZkDSVaEp"},"source":["countries = pd.concat([countries_left, countries_right], axis=1)\n","countries"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R_Jeyp3SWFiY"},"source":["Now the columns from ``countries_left`` and the columns from ``countries_right`` are combined into one dataframe."]},{"cell_type":"markdown","metadata":{"id":"pGhU4SrTyaQ9"},"source":["### Merging (one-to-one)"]},{"cell_type":"markdown","metadata":{"id":"GqbMKsiyWvVx"},"source":["Now suppose you would like to combine the life satisfaction data (``satisfaction``) with the trust data (``trust``). Both datasets contain information on several countries and you would like to combine the data in a way such that the countries are matched. How could this be done? You could try to concatenate the two datasets, but this is very risky. It will not work if the number  or order of the countries differs and you may get things mixed up. It would be better to **combine the data based on the index or the values of some column(s)** (e.g. the country code).\n","\n","The **``merge`` function or method** (`merge` exists as a function and as a method) allows you to do this. The basic syntax is\n","\n","```python\n","new_df = pd.merge(left_df, right_df, ...) # function\n","new_df = left_df.merge(right_df, ...)     # method\n","```\n","\n","where `left_df` and `right_df` are the two dataframes you want to combine. In the examples below, we will use the method syntax.\n","\n","Let's take a look at our two dataframes:"]},{"cell_type":"code","metadata":{"id":"ysaVhoZ1YQfY"},"source":["satisfaction.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zq-Achmor5sy"},"source":["trust.head(7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hscSeDtscy2b"},"source":["Before we can merge the dataframes, we need to decide **on what we want to merge them**. We can merge dataframes **by the index or by column values**. The merge method has the following parameters to specify this:\n","* **``left_index``**: Set to ``True`` if the left dataframe should be **merged on the index**\n","* **``right_index``**: Set to ``True`` if the right dataframe should be **merged on the index**\n","* **``left_on``**: Specify what **column(s)** from the left dataframe should be taken for the merge\n","* **``right_on``**: Specify what **column(s)** from the left dataframe should be taken for the merge\n","* **``on``**: Specify the name of the **column(s)** for the merge if the column name(s) is/are the **same in both datasets**\n","\n","Let's try **merge by the index of both dataframes**:"]},{"cell_type":"code","metadata":{"id":"69yWh3-YfGce"},"source":["df = satisfaction.merge(trust,\n","                        left_index=True,   # use index from left dataframe for merge\n","                        right_index=True)  # use index from right dataframe for merge\n","df.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqlsi7WFgf5k"},"source":["What happened? Since the index is not the same between the two datasets (country names in `satisfaction` and country codes in `trust`), there were no matches and we created an empty dataset.\n","\n","In many cases, you will have to **merge on column values** instead of the index. In our case, we could merge on the country code. The country code is in column ``code`` in ``satisfaction`` (the left dataframe) and in the index in ``trust``(the right dataframe). So we have to merge on column `code` for the left dataframe and on the index for the right dataframe:"]},{"cell_type":"code","metadata":{"id":"DcvSVoUcf29v"},"source":["df = satisfaction.merge(trust,\n","                        left_on=\"code\",\n","                        right_index=True)\n","\n","df.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXDb5SfYkx5K"},"source":["> <font color = 4e1585>SIDENOTE: Even though `country_code` is the index in the right dataframe and not a column, we can treat it in `merge()` as if it was a column; `merge()` is smart enough to understand what we mean. That is, we can also merge the datasets as follows:\n",">\n",">\n",">```python\n","df = satisfaction.merge(trust,\n","                        left_on=\"code\",\n","                        right_on=\"country_code\")\n","```\n",">\n","><font color = 4e1585>A slight difference is that in the second variant of the code the index is not passed on to the new dataframe (which makes sense because the index is not the same in the two datasets).\n",">\n",">\n","><font color = 4e1585>Moreover, you can also **merge on several columns**. For example, if you worry that different countries may have the same country code, you could additionally match on continent. Observations are then only merged if both the country code and the continent are the same:\n",">\n","> ```python\n","> df = satisfaction.merge(trust,\n","                        left_on=[\"code\", \"continent\"],\n","                        right_on=[\"country_code\", \"continent\"])\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iNAQwPmfi5P1"},"source":["Let's think a bit more closely about what happened when we merged the ``satisfaction`` and the ``trust`` dataset. Consider the length of the two datasets:"]},{"cell_type":"code","metadata":{"id":"FTaU19ROmVkp"},"source":["print(len(satisfaction))\n","print(len(trust))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5J5w4jJ41Su"},"source":["Clearly, there must be countries that are in ``satisfaction`` but not in ``trust``. There may also be countries that are in ``trust`` but not in ``satisfaction``. How does the ``merge`` method handle these cases?\n","\n","By default, ``merge`` performs an ``inner join`` -- only observations that are in both dataframes are included. This is why our merged dataframe ``df`` has fewer observations than ``satisfaction`` and ``trust``:"]},{"cell_type":"code","metadata":{"id":"R92t5SkF7xTS"},"source":["print(len(df))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JG19uExE5_dg"},"source":["\n","\n","The**``how`` parameter allows you to specify what observations should be included** in the merged dataframe. There are 4 possibilities:\n","\n","* **``inner`` join**: Only observations that are in *both* dataframes are included. This is the default.\n","* **``outer`` join**: *All* observations are included.\n","* **``left`` join**: All observations from the *left* dataset (i.e. ``satisfaction``) are included.\n","* **``right`` join**: All observations from the *right* dataset (i.e. ``trust``) are included."]},{"cell_type":"markdown","metadata":{"id":"C1QsDK7E8fh0"},"source":["Let's perform an outer join, so we do not loose any observations:"]},{"cell_type":"code","metadata":{"id":"pnnY_X6Ofe-F"},"source":["df = satisfaction.merge(trust,\n","                        how=\"outer\",  # set type of join\n","                        left_on=\"code\",\n","                        right_on=\"country_code\",\n","                        indicator=True)  # add a column with merging information\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xsdS7z9M9OJZ"},"source":["Since we set the `indicator` parameter to `True`, a column named ``_merge`` was added to the dataframe that contains information on the source of an observation. Let's take a look at it:"]},{"cell_type":"code","metadata":{"id":"4XGf7YRw9Eg9"},"source":["df[\"_merge\"].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ql2F9llS-PL"},"source":["As we can see, most of the observations only appeared in the ``satisfaction`` dataframe, some appeared in both dataframes and very few only appeared in the ``trust`` dataframe.\n","\n","> <font color = 4e1585>SIDENOTE: Merging datasets from different sources often requires a lot of tedious data cleaning. For example, if you merge on country names, the spelling of these names may differ across datasets meaning that these countries will not be merged. It may be a good idea to start with an outer merge and inspect the observations that appear only in one of the datasets. If available, (standardized) codes are usually much better for merging than names.  "]},{"cell_type":"markdown","metadata":{"id":"B17Zd81619dI"},"source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","Consider the following two dataframes:  "]},{"cell_type":"code","metadata":{"id":"ipUQkwB73Rwj"},"source":["my_data1 = satisfaction.loc[[\"Switzerland\", \"Tanzania\", \"Peru\", \"China\"],\n","                            [\"code\", \"life_satisfaction\"]].reset_index()\n","\n","my_data2 = satisfaction.loc[[\"Tanzania\", \"India\", \"Peru\", \"China\"],\n","                            [\"code\", \"gni_per_capita\", \"workhours\"]].reset_index()\n","my_data2.loc[3, \"country\"] = \" People's Republic of China\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYAp9IWZ4MDM"},"source":["my_data1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgUaR2qS5hWa"},"source":["my_data2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPi-Yf3m5zWb"},"source":[">  <font color='teal'> How could you combine them into one keeping all observations from ``my_data1``?\n"]},{"cell_type":"code","metadata":{"id":"SGeKcEPnjHMC"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_M-A3lEH5_Ah"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S42N4JTf6Efh"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ehNxCfb4sbau"},"source":["### Many-to-one merging"]},{"cell_type":"markdown","metadata":{"id":"fj8MSG5r-9Es"},"source":["Up to now, we have only conducted **one-to-one joins**. Each observation in your left dataset was merged to one observation from the right dataset (or to none, if none was found). Sometimes you will also want to conduct **many-to-one** joins. This means that several observations from your left dataset will be merged to the same observation in your right dataset. Consider the following two example datasets:"]},{"cell_type":"code","metadata":{"id":"yxtIvmbQJPLa"},"source":["df1 = pd.DataFrame({\"year\": [2000, 2019, 2000, 2019],\n","                    \"gdp_per_cap\": [37868, 81994, 411, 1122]},\n","                   index=[\"Switzerland\", \"Switzerland\", \"Tanzania\", \"Tanzania\"])\n","df1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFPByDSPJZDy"},"source":["df2 = pd.DataFrame({\"continent\": [\"Europe\", \"Africa\"]},\n","                   index=[\"Switzerland\", \"Tanzania\"])\n","df2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_Rl69_MRWUb"},"source":["How could you merge these two datasets? Performing many-to-one joins with pandas is straightforward, as **pandas will infer automatically what kind of join to perform**:"]},{"cell_type":"code","metadata":{"id":"5Lq7FgUUIt6B"},"source":["df1.merge(df2, left_index=True, right_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Before you merge, always be sure that you are perfectly aware of the structure (especially duplicates) of your data! Consider the following example:"],"metadata":{"id":"kmkFf4LJjSZa"}},{"cell_type":"code","source":["df_dup = pd.DataFrame({\"continent\": [\"Europe\", \"Africa\"]},\n","                      index=[\"Switzerland\", \"Switzerland\"])  # Switzerland ist duplicated\n","df1.merge(df_dup, left_index=True, right_index=True,\n","          how=\"left\")  # introduces duplicates on the left side as well!\n","\n","df_dup.index.is_unique"],"metadata":{"id":"A6UCyVmwjklZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xcqf5hj_SXX2"},"source":["> <font color = 4e1585>SIDENOTE: The merge method also allows you to perform **many-to-many** or **one-to-many** joins. If you would like know more about different types of joins, see, for example: https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html"]},{"cell_type":"markdown","metadata":{"id":"JHCk8rphxA-c"},"source":["## Grouping data"]},{"cell_type":"markdown","metadata":{"id":"MevQ4Wq9_lu1"},"source":["Our life satisfaction data contains a variable classifying the countries by income level. Suppose you would like to look at the **average life satisfaction by income group**. How could we do this? One way would be to filter the data and print the result for each country group:"]},{"cell_type":"code","metadata":{"id":"l20B7MZnyYqp"},"source":["satisfaction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u25n5V8ZAECd"},"source":["print(satisfaction.loc[satisfaction[\"income_level\"] == \"High income\",\n","                       \"life_satisfaction\"].mean())\n","print(satisfaction.loc[satisfaction[\"income_level\"] == \"Upper middle income\",\n","                       \"life_satisfaction\"].mean())\n","# etc."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"koywmWsTAwu5"},"source":["This can get very tedious, especially if you have many categories/groups. The **``groupby()`` method allows you to split your data into groups and to easily compute summary statistics (or do operations) for each group**. Let's group our data by income level:"]},{"cell_type":"code","metadata":{"id":"XrE8AnQRB0GC"},"source":["grouped_df = satisfaction.groupby(\"income_level\")\n","print(grouped_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aDST83XHDDOF"},"source":["Using the **``get_group()`` method**, we can retrieve all observations belonging to a particular group:"]},{"cell_type":"code","metadata":{"id":"NQOHnBxfCfrH"},"source":["grouped_df.get_group(\"Low income\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZfKBPKeDcp9"},"source":["Now we can compute the mean (or other summary statistics) for each group:"]},{"cell_type":"code","metadata":{"id":"8R-H_VBfDa12"},"source":["grouped_df[\"life_satisfaction\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3vZnVOvYCMT"},"source":["We can also use ``groupby()`` to create an aggregated dataframe:"]},{"cell_type":"code","metadata":{"id":"hFfZMw_GYUg-"},"source":["ls_byincome = grouped_df[\"life_satisfaction\"].agg([\"mean\", \"median\", \"count\"])\n","ls_byincome"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q7KWyT0yujF-"},"source":["If you want to have the group label as a data column rather than the index, you can add `reset_index()`:"]},{"cell_type":"code","metadata":{"id":"aHP6DaPvu8UI"},"source":["def mean2(x):\n","    return x.mean()\n","\n","\n","grouped_df[\"life_satisfaction\"].agg([\"mean\", \"median\", \"count\", mean2]).reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JccMj_KvD4aQ"},"source":["><font color = 4e1585> SIDENOTE: You can also group your data by several columns (e.g. ``df.groupby([\"income_level\", \"continent\"])``. If you want to know more about grouping data, see, for example:\n","* https://pandas.pydata.org/docs/user_guide/groupby.html"]},{"cell_type":"markdown","metadata":{"id":"-QkQtAtEUOkz"},"source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","You would like to know how many hours people work in a typical country on each continent. Use the ``groupby()`` method compute the median of `workhours` by continent!"]},{"cell_type":"code","metadata":{"id":"2_qPV-RqUPnt"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzvXTgOZXBId"},"source":[">  <font color='teal'> Now create a summary dataframe called ``workhours_by_continent`` with the median of `workhours` and the number of countries by continent."]},{"cell_type":"code","metadata":{"id":"seLEw2mdWbqo"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oYbXE5_aZ9XB"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["## Reshaping data"],"metadata":{"id":"R_Mov82p2tIQ"}},{"cell_type":"markdown","source":["Two-dimensional data can often be displayed in two different formats: **long** or **wide**. Consider the following dataframe:"],"metadata":{"id":"tQiOn2gF2vg4"}},{"cell_type":"code","source":["df_long = pd.DataFrame({\"country\": [\"Switzerland\", \"Switzerland\", \"Tanzania\", \"Tanzania\"],\n","                        \"year\": [2000, 2019, 2000, 2019],\n","                        \"gdp_per_cap\": [37868, 81994, 411, 1122]})\n","df_long"],"metadata":{"id":"ED-UhnMB3Q3J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We call this dataframe **long** because there are multiple/repeated observations (gdp per year) per observational unit (country). Another representation of the data would be to have each country just once and have additional columns which describe the gdp at different years:"],"metadata":{"id":"j9CA3kPi3WTw"}},{"cell_type":"code","source":["df_wide = df_long.pivot(index=\"country\", columns=\"year\", values=\"gdp_per_cap\")\n","print(df_wide)\n","print(df_wide.columns)\n","print(df_wide.index)"],"metadata":{"id":"7W_VmdNI3y2e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["That does not look very clean as we get hierarchical columns. We can solve that by resetting the index:"],"metadata":{"id":"_KvbmmwyHoQN"}},{"cell_type":"code","source":["df_wide = df_wide.reset_index()\n","df_wide"],"metadata":{"id":"-4O-kPilIJ2U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Further, you might consider to first change the values of ``year`` in a way that they are proper column names, e.g. ``\"gdp_2000\"`` instead of ``2000``."],"metadata":{"id":"Vfpfxu0O8f85"}},{"cell_type":"code","source":["df_long[\"colnames\"] = \"gdp_\" + df_long[\"year\"].astype(str)  # <- not ideal\n","df_wide = df_long.pivot(index=\"country\", columns=\"colnames\",\n","                        values=\"gdp_per_cap\").reset_index()\n","df_wide"],"metadata":{"id":"lJ7hLhRM8qvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the other direction you can also reshape from a wide to a long format using ``melt()`` or ``wide_to_long()``:"],"metadata":{"id":"m_U4lC5C-H2H"}},{"cell_type":"code","source":["df_long2 = pd.melt(df_wide, id_vars=\"country\",\n","                   value_vars=[\"gdp_2000\", \"gdp_2019\"],\n","                   var_name=\"year\",\n","                   value_name=\"gdp_per_cap\")\n","df_long2[\"year\"] = (df_long2[\"year\"].str.split(\"_\").str[1]\n","                    .astype(int))  # change values from e.g. \"gdp_2000\" to 2000 (integer)\n","df_long2"],"metadata":{"id":"xLA2C7Ni-WJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reshaping tasks can often be pretty complicated and confusing. You can read additional information in the pandas reference: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html>. If you run into problems with reshaping: start small! Use tiny examples, try your code, and carefully inspect what it does."],"metadata":{"id":"9WgG6ZczJxON"}},{"cell_type":"markdown","source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","Generate the following dataframe:"],"metadata":{"id":"S-1yZ2NXYPQ-"}},{"cell_type":"code","source":["df = pd.DataFrame({\"name\": [\"John Smith\", \"Jane Doe\", \"Mary Johnson\"],\n","                   \"treatmentA\": [5, 10, 8], \"treatmentB\": [12, 10, 9]})\n","df"],"metadata":{"id":"0iSpvYkwU0uG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n",">  <font color='teal'> Reshape the dataset in a way that you have a column ``treatment`` with possible values ``A`` and ``B`` and the measured value as ``value``. Assign the result to a new dataframe ``df_long``."],"metadata":{"id":"bzMplB7hZFU7"}},{"cell_type":"code","source":[],"metadata":{"id":"9iUnkVh2YnU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We might want to clean the new column a bit:"],"metadata":{"id":"JNU7TlOhUW1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n",">  <font color='teal'> Now, reshape the ``df_long`` dataframe back to a wide format."],"metadata":{"id":"ZEMEAN5Dal_W"}},{"cell_type":"code","source":[],"metadata":{"id":"eV0nCiRTZc2_"},"execution_count":null,"outputs":[]}]}
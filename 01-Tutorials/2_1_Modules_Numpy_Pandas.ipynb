{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Gwwx6YFTV9Vt"},"source":["*Part 2: Python for Data Analysis I*\n","# Introduction to Modules, NumPy and Pandas #"]},{"cell_type":"markdown","metadata":{"id":"yUcRodjTarKg"},"source":["## Getting help"]},{"cell_type":"markdown","metadata":{"id":"FMtuELY0au2Z"},"source":["In this class we can not cover all aspects of Python. If you want more details, you can consult, for example, the **Python Standard Library Reference** at https://docs.python.org/3/library/ or the **Language Reference** at https://docs.python.org/3/reference/. But be warned: the amount of detail in these sources can be overwhelming. For **quick and easy-to-understand overviews** of different topics see, for example, https://www.w3schools.com/python/.\n","\n","For an introduction to modules, numpy and pandas, see:\n","*  https://www.w3schools.com/python/python_modules.asp\n","*  https://www.w3schools.com/python/numpy_intro.asp\n","*  https://www.w3schools.com/python/pandas/default.asp\n","\n","If you get stuck or don't remember how to do something, it is usually a good idea to **Google** your problem. Python has a large (and fast-growing) community and you will probably find answers to most of your questions online (e.g. on **Stack Overflow** or in a **Youtube tutorial**)."]},{"cell_type":"markdown","metadata":{"id":"JTfsCAf4UOr8"},"source":["## Importing modules"]},{"cell_type":"markdown","metadata":{"id":"zw13ZJnYU5G6"},"source":["Up to now, we have only worked with built-in functions and data types (i.e. classes). However, there is a large number of **modules** with additional functions, classes etc. you can use (you can also easily create your own modules, see below). For example, the ``math`` module provides many useful mathematical functions:"]},{"cell_type":"code","metadata":{"id":"HnVKOotiYjSK"},"source":["import math   # import the math module with the import keyword\n","help(math)    # Get documentation for the math module"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VPKKeej_bLU3"},"source":["Once you have imported a module, you can use its functions by specifying the name of the module, a dot, and the name of the relevant function:"]},{"cell_type":"code","metadata":{"id":"2U-CVU1YbK5H"},"source":["print(math.cos(3.5))\n","print(math.log(5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SALpl3_Gbiij"},"source":["It may be tedious to type ``math`` every time you want to use a function from the math module (particularly for modules with longer names). Python allows you to specify a shorter name when you import a module:"]},{"cell_type":"code","metadata":{"id":"k91gFlUKZ_1s"},"source":["import math as mt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoXTEpmDbhwq"},"source":["print(mt.cos(3.5))\n","print(mt.log(5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VrihWPAuf2h2"},"source":["You can also import only a specific function from the math module using the ``from`` keyword. If you do this, the function will be imported into the **global** scope and can be used directly without module prefix:"]},{"cell_type":"code","metadata":{"id":"aKtT2Tbmf14m"},"source":["from math import cos\n","cos(3.5)  # Now you can use the cos function directly"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iqtbIKOKdxQH"},"source":["Some modules (like the math module) are part of the *Python Standard Library* and are thus always available, but **most modules need to be installed** before you can import and use them the first time (see here for a list of pre-installed modules: https://docs.python.org/3/py-modindex.html).\n","\n","\n","\n","To install a module, you can **type ``pip install`` followed by the name of the module** in the command line (e.g. Windows Power Shell, Anaconda Prompt or console within your IDE/Editor):"]},{"cell_type":"code","metadata":{"id":"o0wlA61BgZs4"},"source":["pip install numpy  # install the numpy module we will get to know in the next tutorial"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nayp5TUICJn1"},"source":["><font color = 4e1585> SIDENOTE: If you have installed Anaconda, you can also use ``conda install`` instead of ``pip install``."]},{"cell_type":"markdown","metadata":{"id":"Gu5fkFg1hP8I"},"source":["If you work with Colab, you usually don't have to do this as most modules are already installed in the cloud you are working on."]},{"cell_type":"markdown","metadata":{"id":"ebI6ZeF5Y8uW"},"source":["You can also write your own modules (either in Python or in C), save them on your computer and import them (or upload somethere so others can use them as well). Writing your own module in Python is as simple as writing some functions, classes or variables into a Python script and saving it under some name (in an appropriate place (see https://www.w3schools.com/python/python_modules.asp). If you want to import your module, you just type ``import`` followed by the name of your file (e.g. ``import my_module``)."]},{"cell_type":"markdown","source":["Writing your own modules in python is very straightforward. To show you a minimalistic example, have a look at this .py file: <http://farys.org/daten/myhelpers.py>. It holds the function my_divide from the last tutorial as well as our own MyStr class that has a reverse method. We can now easily import this file as a module and use the defined functions, classes and methods:\n"],"metadata":{"id":"oZ7JUcrvbN6k"}},{"cell_type":"code","source":["!wget -O myhelpers.py http://farys.org/daten/myhelpers.py # this needs to be in the right\n","                                                          # place, therefore we download it\n","\n","# this in not needed if you work locally with an IDE."],"metadata":{"id":"l-zoDE2tdP4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import myhelpers as my\n","\n","sentence = my.MyStr(\"Testing my own module...\")\n","print(sentence.reverse())\n","\n","# you could also import globally:\n","from myhelpers import my_divide\n","print(my_divide(8, 2))"],"metadata":{"id":"RlATXibLfvxn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3wj3FwEYu_X"},"source":["><font color = 4e1585> SIDENOTE: Apart from modules, you may also hear people talk about **packages or libraries**. You can think of them as collections of modules."]},{"cell_type":"markdown","metadata":{"id":"DZ69nsJuDCI_"},"source":["## Introduction to numpy"]},{"cell_type":"markdown","metadata":{"id":"-vNicsnQDYs2"},"source":["Imagine you want to **do data analysis or machine learning with Python**. Of course, you could write all your data into one or several **lists**. If you work with data, you have to do **element-wise operations** very often, meaning that you would always have to write a loop, a list comprehension or a function. This is not only **a lot of tedious and error-prone work**, but also **computationally inefficient** (looping through built-in data structures such as lists or dictionaries is slow because these data structures are so general).\n","\n","Consider the following example where we have a dataset with the weights and heights of some people and we want to compute the BMI for each of them:"]},{"cell_type":"code","metadata":{"id":"U0Q6KMWYFoeM"},"source":["# Create list with height and weight of some people\n","my_dataset = [[\"Mary\", \"Tim\", \"Rosa\", \"Nina\"],\n","              [\"f\", \"m\", \"f\", \"f\"],\n","              [56, 73, 85, 54],\n","              [1.60, 1.87, 1.73, 1.50]]\n","\n","my_columns = [\"name\", \"sex\", \"height\", \"weight\"]\n","\n","# Add body mass index to list\n","bmi = [kg/(m**2) for kg, m in zip(my_dataset[2], my_dataset[3])]\n","my_dataset.append(bmi)\n","my_columns.append(\"bmi\")\n","\n","# Check result\n","print(my_columns)\n","print(my_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dh8MGbyDDvm0"},"source":["This is quite some coding for something you may have to do quite often. The **numpy and pandas modules offer a much easier and more efficient** (up to 50x faster) way to do such operations. You will probaby use pandas more often, but it is still useful to start by taking a **brief look at numpy**."]},{"cell_type":"markdown","metadata":{"id":"npY2E6b8Ja55"},"source":["Numpy (or: NumPy) stands for Numerical Python and is one of the most commonly used Python libraries. By convention, it is always imported as np:"]},{"cell_type":"code","metadata":{"id":"UaTNHTC3Du_l"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYZ0ucj_K7Tn"},"source":["The main purpose of Numpy is to provide functionality to **work with arrays**. Let's create one:"]},{"cell_type":"code","metadata":{"id":"QNioIFx7LJpZ"},"source":["my_array = np.array([1, 2, 3, 4, 5])  # Create numpy array from list\n","\n","print(my_array)\n","type(my_array)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tnd7pnafLMrA"},"source":["But what is an array? It is very similar to a list, but it is less general and thus allows for much more efficient computation. If you are familiar with linear algebra, you can think of arrays as vectors or matrices."]},{"cell_type":"code","metadata":{"id":"MQRoSBiXLMEH"},"source":["arr1 = np.array([2, 4, 6, 8, 10])\n","arr2 = np.array([5, 4, 3, 2, 1])\n","\n","print(arr1*2)\n","print(arr1-2)\n","print(arr1+arr2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KHiOFH0MMn1i"},"source":["Other than lists, arrays can only contain **elements of the same type**:"]},{"cell_type":"code","metadata":{"id":"bli75cCpMm1T"},"source":["my_list = [\"a\", 1, True, 3.25]\n","arr3 = np.array(my_list)\n","print(arr3)  # all elements were converted to strings!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdhQf2awnXwi"},"source":["><font color = 4e1585> SIDENOTE: To be precise, the data type in this case is ``U4``, a 4-character unicode string.\n",">\n",">```\n"," print(arr3.dtype)\n","```\n",">\n","><font color = 4e1585>If you are interested in data types in numpy, see here: https://numpy.org/doc/stable/reference/arrays.dtypes.html\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_hHcDkH1kW11"},"source":["Many of the things you can do with lists also work with arrays. For example, you can do **indexing and slicing** in the usual way (the returned result is still an array, not a list):"]},{"cell_type":"code","metadata":{"id":"w1GxqtSCkyZL"},"source":["print(arr1[0])      # Get first element\n","print(arr1[-1])     # get last element\n","print(arr1[1:4])    # get first second to forth element\n","print(arr1[:3])     # get first three elements"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQePnPCdtvVn"},"source":["A convenient feature is that you can **filter arrays** using booleans:"]},{"cell_type":"code","metadata":{"id":"1dgR0VfwqcTf"},"source":["arr1[[False, False, True, True, True]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QLO4KmFiqhcY"},"source":["This is often very useful because it allows you to **select values based on a condition**:"]},{"cell_type":"code","metadata":{"id":"3zqXOHqrtu2P"},"source":["# Filter values that are greater than 3\n","my_filter = arr1 > 5\n","print(my_filter)\n","print(arr1[my_filter])\n","\n","# Or simply:\n","print(arr1[arr1 > 5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1rQE7oDtOLA7"},"source":["The arrays we have seen so far were one-dimensional. You can also create **multidimensional arrays**:"]},{"cell_type":"code","metadata":{"id":"Eojzt7hWOBbd"},"source":["array_2D = np.array([[1, 2, 3],\n","                     [4, 5, 6]])\n","array_3D = np.array([[[0, 0, 0, 0], [1, 1, 1, 1]],\n","                     [[2, 2, 2, 2], [3, 3, 3, 3]]])\n","print(\"2-D array:\")\n","print(array_2D)\n","print(\"3-D array:\")\n","print(array_3D)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PBV9B7xaivAI"},"source":["You can look the **shape of an array** using the ``shape`` attribute:"]},{"cell_type":"code","metadata":{"id":"EzrY3RFtM5Dl"},"source":["print(array_2D.shape)  # shape is an attribute, not a method (so you don't use parantheses)\n","print(array_3D.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWhf0FDyM5nm"},"source":["The length of the tuple that is returned correponds to the number of dimensions of the array, while the values (e.g. 2, 2, and 4 for the second example) indicate the number of elements in each dimension (from outermost to innermost: the array has two top level elements, that each contain two lower level elements, that each contain 4 elements).\n","\n","You can change the shape of an array using the ``reshape()`` method:"]},{"cell_type":"code","metadata":{"id":"1kHeAswPkGuw"},"source":["array_2D.reshape(3, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSDwf2uwsk-l"},"source":["There is much more you can do with arrays. You can join and split them, iterate through them, search them etc. If you are interested, you will find many great tutorials online. For example: https://www.w3schools.com/python/numpy_intro.asp"]},{"cell_type":"markdown","metadata":{"id":"_TMNzewBsO33"},"source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","Import numpy and create a one-dimensional array with the numbers from 0 to 5 (i.e. 0, 1, 2, 3, 4, 5).\n"]},{"cell_type":"code","metadata":{"id":"Df20Yx6YtBRd"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrW2_azZoFnc"},"source":["> <font color='teal'> Print (a) the last element in the array and (b) all elements that are greater than 3."]},{"cell_type":"code","metadata":{"id":"f4Icv1bcs2SG"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i4ApHx0Goji6"},"source":["> <font color='teal'> Can you reshape your array to get the following array?\n",">```\n","array([[0, 1, 2],\n","       [3, 4, 5]])\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"yJxOtUp5ohzZ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgGlvpfVtcJb"},"source":["Generally speaking, **Numpy** is a good choice when you have tasks that deal with homogeneous vectors, matrices and more-dimensional objects, e.g.:"]},{"cell_type":"code","source":["from skimage import io\n","photo = io.imread('http://farys.org/daten/cat_photo.jpg')\n","type(photo)  # this is simply a numpy.ndarray"],"metadata":{"id":"yW7ZnOFQVPMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["photo.shape"],"metadata":{"id":"SVTv5VIHWST1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["photo[0, 0:10, 0:4]"],"metadata":{"id":"9MKdjTEYJS7q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, there is information on each pixel for each of the three basic colors."],"metadata":{"id":"tzII2ZklWY_T"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.imshow(photo)"],"metadata":{"id":"egccZS1-WfXl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As this is a homogeneous array of pure numbers, it is straightforward to do some operations on the image:"],"metadata":{"id":"_aRmVSvsWoHW"}},{"cell_type":"code","source":["plt.imshow(photo[:, ::-1])  # flipping the column-dimension -> mirror image"],"metadata":{"id":"jX3_ZjzKW2I2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(photo[150:300, 260:450])  # crop image"],"metadata":{"id":"n-OySN5GXH_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_sepia_filter(img_array):\n","    # Define the values of the sepia filter\n","    sepia_filter = np.array([[0.393, 0.769, 0.189],\n","                             [0.349, 0.686, 0.168],\n","                             [0.272, 0.534, 0.131]])\n","\n","    # Apply the sepia filter to the image array\n","    sepia_image = np.dot(img_array, sepia_filter.T)\n","\n","    # Clip the values to make sure they are in the range [0, 255]\n","    sepia_image = np.clip(sepia_image, 0, 255)\n","\n","    # Convert the image back to uint8 data type\n","    sepia_image = sepia_image.astype(np.uint8)\n","\n","    # Return the sepia image array\n","    return sepia_image\n","\n","\n","vintage_cat = apply_sepia_filter(photo)\n","plt.imshow(vintage_cat)"],"metadata":{"id":"SWNm0FBgXzg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can have a look at more simple examples here: https://scikit-image.org/docs/stable/auto_examples/"],"metadata":{"id":"9x_8YcoSi1Xl"}},{"cell_type":"markdown","source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","Can you compress the image by a factor of 100 by just using every 10th row and every 10th column?</font>\n"],"metadata":{"id":"OHJXAW-FkKuk"}},{"cell_type":"code","source":[],"metadata":{"id":"G_8c8phOyEzp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  ---\n","\n",">  <font color='teal'> Can you swap the values for red and blue in the photo?\n","\n","> <font color='violet'> Hint: </font><font color='white'>You could flip/invert the order of the third dimension of the array which holds the RGB-values. Inverting the order (RGB -> BGR) will effectively take the blue-value for red and the red-value for blue."],"metadata":{"id":"DjYEE9DIyFKw"}},{"cell_type":"code","source":[],"metadata":{"id":"5DRLRrH6yQRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCD74npeu7MD"},"source":["## Introduction to pandas"]},{"cell_type":"markdown","metadata":{"id":"r6dRPdpwvA8T"},"source":["**Numpy** is fast and makes numerical computations much easier, but it lacks some of the functionality we would like to have when we work with statistical data. For example, we **cannot give labels to the rows and columns** (e.g. \"variable names\" in statistics) and we **cannot have different data types in the same array** (i.e. an array cannot hold a \"string variable\" and a \"numeric variable\" at the same time). This means that we have to use the numeric indices to access parts of the dataset and may need to do tedious type conversions (or save different parts of the data in different arrays) if want to do computations:"]},{"cell_type":"code","metadata":{"id":"IQN-LAsywbDR"},"source":["# Create dataset as numpy array\n","my_dataset = np.array([[\"Mary\", \"Tim\", \"Rosa\", \"Nina\"],\n","                       [\"f\", \"m\", \"f\", \"f\"],\n","                       [56, 73, 85, 54],\n","                       [1.60, 1.87, 1.73, 1.50]])\n","print(my_dataset.dtype)  # array of strings was created\n","\n","# Add BMI to array\n","bmi = my_dataset[2].astype(np.float64)/(my_dataset[3].astype(np.float64))**2\n","my_dataset = np.append(my_dataset, bmi).reshape(5, 4)\n","my_dataset.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aoeN8_MThlEI"},"source":["**Pandas builds on top of numpy and introduces these functionalities!** So let's get started with it.\n","\n","By convention, pandas is always **imported as pd**:"]},{"cell_type":"code","metadata":{"id":"OdFPyWinohc5"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3h8maPWyFk9"},"source":["\n"," We will begin with the **basic object types** in pandas: **pandas series** and **pandas dataframes**."]},{"cell_type":"markdown","metadata":{"id":"EMSpfKBj9MmZ"},"source":["###Pandas series"]},{"cell_type":"markdown","metadata":{"id":"zryMugaO6Q1k"},"source":["Pandas **series are very similar to one-dimensional numpy array**. You can think of them as a column in a data frame (a statistical variable). Let's create one:"]},{"cell_type":"code","metadata":{"id":"oGnUX4iO6Qa9"},"source":["weight_list = [56, 73, 85, 54]\n","weight = pd.Series(weight_list)  # Or directly: pd.Series([56, 73, 85, 54])\n","weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ryzm8R-Sf5B3"},"source":["There is one key difference to numpy arrays: Pandas series also have **labels** that you can customize. This can be done using the **index parameter** (i.e. by providing a list of labels as arguments):  "]},{"cell_type":"code","metadata":{"id":"jySlgz5Z7Liv"},"source":["weight = pd.Series(weight_list,\n","                   index=[\"Mary\", \"Tim\", \"Rose\", \"Nina\"])  # index parameter\n","                                                           # takes a list as argument!\n","weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNAEURRtjrz1"},"source":["Now you can also access values using the labels you specified:"]},{"cell_type":"code","metadata":{"id":"XH1Btjghj21M"},"source":["print(weight[\"Tim\"])  # Access through labels\n","print(weight[1])      # Access through positional index works too"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ExpSxnbs87L7"},"source":["A (labeled) pandas series can also be built from a dictionary"]},{"cell_type":"code","metadata":{"id":"Qy_5RVbL89sa"},"source":["weight_dict = {\"Mary\": 56, \"Tim\": 73, \"Rose\": 85, \"Nina\": 54}\n","weight = pd.Series(weight_dict)\n","weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5PGvV948LH6"},"source":["><font color = 4e1585> SIDENOTE: We said that pandas series are very similar to (one-dimensional) numpy arrays, but that they additionally have indices/labels. In fact, the values in a pandas series are a numpy array! If you exectute ``type(weight.values)`` (where ``weight`` is a pandas series) you will get ``numpy.ndarray`` as the output. Hence, you can think of pandas series as an object that combines a numpy array with indices/labels."]},{"cell_type":"markdown","metadata":{"id":"ARM9KHNegxNl"},"source":["As you may have guessed, you can directly perform element-wise operations with pandas series:"]},{"cell_type":"code","metadata":{"id":"jg8WbsTeDKHd"},"source":["weight = pd.Series([56, 73, 85, 54],\n","                   index=[\"Mary\", \"Tim\", \"Rose\", \"Nina\"])\n","\n","height = pd.Series([1.60, 1.87, 1.73, 1.50],\n","                   index=[\"Mary\", \"Tim\", \"Rose\", \"Nina\"])\n","\n","BMI = weight/height**2\n","BMI"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnO_JS6ihA1b"},"source":["This is already much more convenient than using lists or numpy arrays. However, it usually does not make sense to have each column as a different object. This is where dataframes come in."]},{"cell_type":"markdown","metadata":{"id":"oQfxQm1T9RIn"},"source":["### Pandas dataframe"]},{"cell_type":"markdown","metadata":{"id":"bO0kVVxe9nxc"},"source":["Dataframes are **(two-dimensional) tables of data** (similar to an Excel spreadsheet or a data table in Stata or SPSS). Let's create one:"]},{"cell_type":"code","metadata":{"id":"y2bUNW3orhl4"},"source":["# Create dataframe from dictionary\n","my_dict = {\"sex\":    [\"f\", \"m\", \"f\", \"f\"],\n","           \"weight\": [56, 73, 85, 54],\n","           \"height\": [1.60, 1.87, 1.73, 1.50]}\n","df = pd.DataFrame(my_dict,\n","                  index=[\"Mary\", \"Tim\", \"Rose\", \"Nina\"])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HwKNE93l1PlI"},"source":["A pandas dataframe consists of three components (called *attributes*):\n","\n","\n","*   **Values**: The data within the table (called *values*)\n","*   **Row indices**: Labels you can specify for each row (called *index*)\n","*   **Column indices**: Labels you can specify for each column (called *column*)\n","\n","Let's have a look at each of these attributes of the dataframe object:\n","\n"]},{"cell_type":"code","metadata":{"id":"DAY-XQpBxzDR"},"source":["print(df.values)\n","print(df.index)\n","print(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0LdvMHlyYl6"},"source":["We have already seen the ``index`` parameter to specify the row labels. Analogously, we can use the ``columns`` parameter to specify the column labels (i.e. \"variable names\"):"]},{"cell_type":"code","metadata":{"id":"sn65H6G_rL3f"},"source":["# Create dataframe from a nested list\n","df2 = pd.DataFrame([[\"f\", 56, 1.60],\n","                    [\"m\", 73, 1.87],\n","                    [\"f\", 85, 1.73],\n","                    [\"m\", 54, 1.50]],\n","                   index=[\"Mary\", \"Tim\", \"Rose\", \"Nina\"],\n","                   columns=[\"sex\", \"weight\", \"height\"])\n","df2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lp48yNumCBCE"},"source":["><font color = 4e1585> SIDENOTE: Usually, you will not create dataframes manually, but you will import them from some file. We will see how to do this next time."]},{"cell_type":"markdown","metadata":{"id":"T0Wt_lQVw-_C"},"source":["You can also **change the labels** of an existing dataframe:"]},{"cell_type":"code","metadata":{"id":"jRw2tdARzgUk"},"source":["# Change labels\n","df2.index = [\"obs1\", \"obs2\", \"obs3\", \"obs4\"]\n","df2.columns = [\"var1\", \"var2\", \"var3\"]\n","df2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Another way to create a dataframe would be zipping lists:"],"metadata":{"id":"o3PXBV9GDUDs"}},{"cell_type":"code","source":["names = [\"Mary\", \"Tim\", \"Rose\", \"Nina\"]\n","sex = [\"f\", \"m\", \"f\", \"m\"]\n","weight = [56, 73, 85, 54]\n","height = [1.60, 1.87, 1.73, 1.50]\n","df3 = pd.DataFrame(zip(sex, weight, height),\n","                   columns=[\"sex\", \"weight\", \"height\"],\n","                   index=names)\n","\n","df3"],"metadata":{"id":"NpcpLxiJDfNm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WUFVk3ql27XQ"},"source":["#### Accessing and adding columns"]},{"cell_type":"markdown","metadata":{"id":"dx7JrfRa0KZw"},"source":["You can **access a column** in a dataframe using the column label:"]},{"cell_type":"code","metadata":{"id":"-5Rd_wa50Jnx"},"source":["df[\"height\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9DzoZLJDkR_"},"source":["type(df[\"height\"])  # selecting a column returns a pandas Series!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Columns can also be accessed as attributes (if they have names without spaces or other special characters):"],"metadata":{"id":"J78dEpZczi9d"}},{"cell_type":"code","source":["df.height"],"metadata":{"id":"kVVwlVg1zsxz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ou7m3J947pCT"},"source":["If you enter a list of columns labels into the indexer (i.e. the ``[]``), you can also **access several columns** at once:"]},{"cell_type":"code","metadata":{"id":"dC-ZtaOu8WBK"},"source":["df[[\"height\", \"weight\"]]  # Don't forget that you need to use\n","                          # double square brackets: [[]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jL9u-bre33bJ"},"source":["**Adding an additional column** is also straightforward. Let's add the BMI column:"]},{"cell_type":"code","metadata":{"id":"vtsFR9c44Tt1"},"source":["df[\"bmi\"] = df[\"weight\"]/df[\"height\"]**2\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BujVD2CRa2YK"},"source":["You could also add new columns manually (but note that the specified list must have the correct length):"]},{"cell_type":"code","metadata":{"id":"03V_nAVsa-CJ"},"source":["df[\"age\"] = [42, 60, 92, 13]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kers_D33xT9o"},"source":["---\n","\n",">  <font color='teal'> **In-class exercise**:\n","Import pandas and create the following dataframe (earnings are per month, workhours per week) and assign it to the variable ``my_df``:\n",">\n",">|  | earnings | workhours |\n",">| :- | -: | :-: |\n",">| Max | 4050 | 45\n",">| Nina | 6000| 30\n",">| Sarah | 2400 | 30\n",">\n",">  \n","<font color='teal'>(You can copy the values from here so you do not have to type everything: names: Max, Nina, Sarah; earnings: 4500, 6000, 2400; workhours: 45, 30, 30)\n",">\n"]},{"cell_type":"code","metadata":{"id":"4XVXitF2xTSY"},"source":["# Create dataframe from dictionary\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5lBqy765zEMg"},"source":[">  <font color='teal'> Add an additional column ``wage`` with the hourly wage for each person. Print this column."]},{"cell_type":"code","metadata":{"id":"5pWn1BVfzDH4"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6bp3L6kMzoFE"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"gk9z9_j27Fer"},"source":["#### Subsetting data"]},{"cell_type":"markdown","metadata":{"id":"VL3jTu6M7JRs"},"source":["We have seen how to access columns. But often you want to do more complicated things, such as accessing rows, accessing combinations of rows and columns, or accessing slices of rows or columns.\n","\n","Appart from the ``[]`` indexer that allows you to access columns (or slices of rows -- but never mind), pandas provides also **two more sophisticated indexers for dataframes: the ``loc[]`` and the ``iloc[]`` indexer**.\n"]},{"cell_type":"markdown","metadata":{"id":"Y02rRQg9XCeP"},"source":["##### **Subsetting with the ``loc[]`` indexer**"]},{"cell_type":"markdown","metadata":{"id":"D3Cb23mjXYK2"},"source":["\n","The ``loc[]`` indexer allows you to access (**loc**ate) data **based on the labels**:"]},{"cell_type":"code","source":["df"],"metadata":{"id":"7MGASkUG2Z1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y5PbaNSI6kKO"},"source":["df.loc[\"Rose\", \"height\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1JYcAVTss23"},"source":["The syntax works as follows:\n","*   *dataframe*``.loc[``*rows*``,`` *columns*``]``\n","\n","This is, you write ``.loc[]`` after your dataframe and, within the brackets,   first specify the rows and then (after the comma) the columns.\n","\n","Appart from selecting **single labels** (as in the example above), you can also select multiple rows and/or columns. One way to do this is by providing a **list of labels**:\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lAr738j-DDqp"},"source":["df.loc[[\"Rose\", \"Mary\", \"Nina\"], [\"height\", \"weight\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztH5AsaWEDPQ"},"source":["The second way to select several rows or columns is through **slicing**:"]},{"cell_type":"code","metadata":{"id":"ckUsqLNSEa4s"},"source":["df.loc[\"Tim\":\"Nina\", \"sex\":\"height\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sAwjX5KFEyPk"},"source":["You already know slicing from lists and strings. The things we have seen there work with pandas dataframes as well:"]},{"cell_type":"code","metadata":{"id":"apD66XHTFI5R"},"source":["# leave end of slice empty (to go to the end)\n","print(df.loc[\"Tim\":, \"sex\":\"height\"])\n","\n","# leave beginning of slice empty (to start from the beginning)\n","print(df.loc[\"Tim\":\"Nina\", :\"height\"])\n","\n","# leave beginning and end empty (to take the entire sequence)\n","print(df.loc[\"Tim\":\"Nina\", :])   # Or just: df.loc[\"Tim\":\"Nina\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dN7pz_JEHKT6"},"source":["<font color = red> As you may have noticed, there is **one key difference**. When we do slicing with lists or strings, the end of the slice is not included. This is different with the ``loc[]`` indexer, where the **end of the slice (i.e. \"height\" or \"Nina\") is always included**!"]},{"cell_type":"markdown","metadata":{"id":"9_WB9PvxIKeE"},"source":["You can also combine the different types of subsetting (single labels, list of labels, slices with labels):"]},{"cell_type":"code","metadata":{"id":"7rNTTB1fIVuY"},"source":["df.loc[[\"Tim\", \"Nina\"], \"sex\":\"height\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jr_zyQUDV_KM"},"source":["As you may have guessed, you cannot only use this syntax to extract parts of your data, buy also to modify your dataframe:"]},{"cell_type":"code","metadata":{"id":"UNzSqYKZWO0y"},"source":["# Modify one value\n","df.loc[\"Tim\", \"weight\"] = 85\n","print(df)\n","\n","# Modify several values\n","df.loc[[\"Tim\", \"Nina\"], \"height\"] = [1.85, 1.58]\n","print(df)\n","\n","df[\"bmi\"] = df[\"weight\"]/df[\"height\"]**2  # Correct body mass index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzAXC9hwX3fe"},"source":["##### **Subsetting with the ``iloc[]`` indexer**"]},{"cell_type":"markdown","metadata":{"id":"dxygRB4wX9v-"},"source":["You can not only select data based on the labels, but also **based on the positional index of the columns or rows**. This is done with the ``iloc[]`` indexer (**i**nteger **loc**ation):"]},{"cell_type":"code","metadata":{"id":"MLZ2_mYuwoly"},"source":["print(df)\n","print(df.iloc[1, 2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6aM5MRU2Y4RF"},"source":["The syntax is as follows:\n","*   *dataframe*``.iloc[``*rows*``,`` *columns*``]``\n","\n","It works just as the ``loc[]`` indexer, but you have to provide the numeric index rather than the label to define the rows and columns you want to select. As usual in Python, counting starts with 0.  \n","\n","As with ``loc[]`` indexer, you can provide **single indices, a list of indices or slices of indices** as arguments to the indexer:"]},{"cell_type":"code","metadata":{"id":"ikzEEBphuCsm"},"source":["print(df.iloc[2, 2])              # single indices\n","print(df.iloc[[1, 3], [0, 2, 3]])  # lists of indices\n","print(df.iloc[:2, 1:3])           # slices of indices"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uhwds_MSc5dp"},"source":["<font color = red> Did you notice something in the slicing example? With the ``iloc[]`` indexer, the **end of the slice is not included**! This means that in this respect, slicing with ``iloc[]`` works like list or string slicing and not like ``loc[]`` slicing!"]},{"cell_type":"markdown","metadata":{"id":"Hy2dFi6jCP2l"},"source":["##### **Boolean indexing**"]},{"cell_type":"markdown","metadata":{"id":"IjKqoZpaO_pX"},"source":["You can also select data based on true/false conditions. This is called **Boolean indexing**. We have already seen it for numpy arrays. It works with pandas dataframes as well:"]},{"cell_type":"code","source":["df"],"metadata":{"id":"4e8UtAVI_Lac"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9H92QpjhPFAm"},"source":["print(df[df[\"age\"] > 17])  # Note that df[\"age\" > 17] would not work!!\n","print(df[df[\"sex\"] == \"f\"])\n","print(df[df[\"age\"].isin([20, 40, 60, 80, 100])])  # isin() checks whether age is\n","                                                  # equal to any of the provided values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nQNTsJdirWC"},"source":["In each of these cases, all **rows for which the condition is true** were selected.\n","\n"," You can also specify multiple conditions:"]},{"cell_type":"code","metadata":{"id":"8TQgNglvh-AQ"},"source":["df[(df[\"bmi\"] <= 18.5) | (df[\"bmi\"] >= 25)]  # or operator: |\n","df[(df[\"age\"] > 17) & (df[\"sex\"] == \"f\")]    # and operator: &"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ADu4uVMSSIYb"},"source":["Boolean indexing also works with the ``loc[]`` indexer. This is how you would typically access a selection of variables for a subset of your observations:"]},{"cell_type":"code","metadata":{"id":"nijLpKdCmnpb"},"source":["df.loc[df[\"age\"] > 17, [\"age\", \"weight\", \"height\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OinKpdYl4ilX"},"source":["If you want to learn more about subsetting, see for example: https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c"]},{"cell_type":"markdown","metadata":{"id":"wxRl8-x_bcIv"},"source":["><font color = 4e1585> SIDENOTE: Above we used code such as ``df[\"name2\"]`` or ``df[[\"name1\",\"name2\",...]]`` to select columns of the dataframe (see \"Accessing and adding columns\"). However, when we do Boolean indexing, rows rather than columns were selected. How does Python know that we want to select rows when we use Boolean indexing, i.e. when we type something like ``df[df[\"age\"] > 17]``? Pandas tries to be smart and decides depending on type of input whether to select columns of rows. If the input is strings, then columns are selected; if the input is booleans, then rows are selected."]},{"cell_type":"markdown","metadata":{"id":"87tYwUHC1aV6"},"source":["\n","\n","---\n","\n","\n",">  <font color='teal'> **In-class exercise**:\n","Consider the following dataframe:"]},{"cell_type":"code","metadata":{"id":"wMm2xAna1mhU"},"source":["labor_df = pd.DataFrame({\"income\":    [4500, 6000, 2400, 4500, 5000],\n","                         \"workhours\": [45, 30, 30, 25, 50],\n","                         \"sex\":       [\"m\", \"f\", \"f\", \"m\", \"f\"],\n","                         \"age\":       [24, 57, 36, 46, 19]},\n","                        index=[\"Max\", \"Nina\", \"Sarah\", \"Paul\", \"Kate\"])\n","\n","labor_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHtJW6A72b5P"},"source":[">  <font color='teal'> Print Sarah's age using the ``iloc[]``  indexer:\n"]},{"cell_type":"code","metadata":{"id":"0GPXAFq-2wfO"},"source":["labor_df.iloc[2, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvj4k8qp2xC-"},"source":[">  <font color='teal'> Print the income and age for all persons from Nina to Paul using the ``loc[]`` indexer."]},{"cell_type":"code","metadata":{"id":"6iuI3UeQ33nP"},"source":["labor_df.loc[\"Nina\":\"Paul\", [\"income\", \"age\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_kJ5z435adY"},"source":[">  <font color='teal'> Now print the data for all women in the dataset."]},{"cell_type":"code","metadata":{"id":"aFFJ8SeN5lCG"},"source":["labor_df.loc[labor_df[\"sex\"] == \"f\", :]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3s7Sfng25z1H"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vZr9PrlhqcH9"},"source":["### Views and copies in pandas*"]},{"cell_type":"markdown","metadata":{"id":"Ep0_jSQdqaoa"},"source":["Just like lists, dicionaries and sets, arrays and dafaframes (or series) are mutable (see first tutorial). This means that they exhibit the same confusing behavior under certain conditions:"]},{"cell_type":"code","metadata":{"id":"4GG8vPlAoGs2"},"source":["array1 = np.array([1, 2, 3])\n","array2 = array1\n","array1[0] = 3\n","\n","print(array1)\n","print(array2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"roVe5d9BoO8u"},"source":["data1 = pd.DataFrame({\"var1\": [1, 2],\n","                      \"var2\": [3, 4]})\n","data2 = data1\n","data1.loc[1] = 0\n","\n","print(data1)\n","print(data2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a1zOWDI_qRfS"},"source":["As you may have guessed, this happens because array1 and array2, as well as data1 and data2, are **different pointers to the same object**.\n","\n","A similar behavior ocurrs if you **assign a slice of your dataframe to a variable**:"]},{"cell_type":"code","source":["df = pd.DataFrame({\"col1\": [1, 2],\n","                   \"col2\": [3, 4],\n","                   \"col3\": [5, 6]})\n","col1 = df.loc[:, \"col1\"]  # Assign first column to variable col1\n","col1[0] = 10000           # Change first value in col1\n","print(col1)\n","df                        # Value is changed in df too!"],"metadata":{"id":"JRRLs2rx8kJB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Depending on the context, pandas will either create a **copy** (new object) or a **view** (pointer to a part of the existing object) when we assign parts of our data to a new variable.\n","\n","![Client Server Model](https://www.dataquest.io/wp-content/uploads/2019/01/view-vs-copy.png)\n","\n","\n","\n","In the code above, only a view was created.  As ``col1`` is no new object but just a pointer to a slice of ``df``, changing it will change ``df`` too (and vice versa).\n","\n"],"metadata":{"id":"3hLj4r_p84Nw"}},{"cell_type":"markdown","source":[" If you want to make true copies of an array, a dataframe or a part of your dataframe, you can **use the copy method** that exists both for numpy arrays and for pandas dataframes (or series):"],"metadata":{"id":"mm_fTViT5F-8"}},{"cell_type":"code","metadata":{"id":"KGEbzqaqqqCA"},"source":["array1 = np.array([1, 2, 3])\n","array2 = array1.copy()\n","array1[0] = 3\n","\n","print(array1)\n","print(array2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wbc5dwuiqiBB"},"source":["data1 = pd.DataFrame({\"var1\": [1, 2],\n","                      \"var2\": [3, 4]})\n","data2 = data1.copy()\n","data1.loc[1] = 0\n","\n","print(data1)\n","print(data2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame({\"col1\": [1, 2],\n","                   \"col2\": [3, 4],\n","                   \"col3\": [5, 6]})\n","col1 = df.loc[:, \"col1\"].copy()\n","col1[0] = 10000\n","print(col1)\n","df"],"metadata":{"id":"B23C-MTm9vev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["><font color = 4e1585> SIDENOTE: Sometimes you will come across the following warning:\n",">\n",">```\n","SettingWithCopyWarning:\n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","````\n",">\n","><font color = 4e1585>This appears when pandas thinks that we might not be aware that we are dealing with a copy rather than a slice. This can not only happen when you assign a part of your dataframe to a variable, but, more generally, when you perform chained operations. In most cases, you will still get the output you expect, but sometimes you won't:\n"],"metadata":{"id":"vCrtIBUw_0pd"}},{"cell_type":"code","source":["df[df[\"col1\"] == 1][\"col2\"] = 1000\n","df  # df is NOT changed"],"metadata":{"id":"TECRS4_jtKss"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["><font color = 4e1585> As a rule of thumb, it is better to use the ``iloc[]`` or the ``loc[]`` indexer rather than the simple ``[]`` indexer (they avoid chaining):"],"metadata":{"id":"ec9COxOivAoD"}},{"cell_type":"code","source":["df.loc[df[\"col1\"] == 1, \"col2\"] = 5000\n","df  # df is changed"],"metadata":{"id":"1Frgg2I-vwut"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["><font color = 4e1585> To be honest, the implementation of views and copies in pandas and the respective warnings is not very transparent and quite confusing. If you want to learn more about them, see, for example:\n","\n","\n","- https://www.dataquest.io/blog/settingwithcopywarning/"],"metadata":{"id":"hM-zr9P_uv6k"}},{"cell_type":"markdown","source":["## Next week\n","\n","In the next session we will deal with pandas in more detail. If you already want to prepare a little, the following videos are recommended:\n","* https://youtu.be/vmEHCJofslg (1:08 h)\n","* https://youtu.be/ZyhVh-qRZPA (Part 3 - 11, very extensive!)\n","* ...or countless other videos on YouTube\n","\n","If you prefer to learn with text rather than videos, this online tutorial (with exercises) is highly recommended:\n","* https://www.kaggle.com/learn/pandas"],"metadata":{"id":"VyfIjhkdvJ7d"}}]}